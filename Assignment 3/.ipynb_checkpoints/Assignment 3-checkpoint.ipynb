{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import random\n",
    "import string\n",
    "import operator\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Bag-of-Words\n",
    "## Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Question 1 ###########\n",
    "# convert both datasets\n",
    "\n",
    "## binary bag-of-words\n",
    "# yelp\n",
    "data1 = pd.read_csv(\"hwk3_datasets/yelp-train.txt\", sep=\"\\t\", header=None)\n",
    "data2 = pd.read_csv(\"hwk3_datasets/yelp-valid.txt\", sep=\"\\t\",  header=None)\n",
    "data3 = pd.read_csv(\"hwk3_datasets/yelp-test.txt\", sep=\"\\t\",  header=None)\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "for i in range(data1[0].count()):\n",
    "    temp = data1[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data1[0][i] = temp\n",
    "\n",
    "for i in range(data2[0].count()):\n",
    "    temp = data2[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data2[0][i] = temp\n",
    "\n",
    "for i in range(data3[0].count()):\n",
    "    temp = data3[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data3[0][i] = temp\n",
    "\n",
    "yelp_train = data1.values\n",
    "yelp_valid = data2.values\n",
    "yelp_test = data3.values\n",
    "\n",
    "# generating top 10000 words\n",
    "pre_list_train = {}\n",
    "\n",
    "for i in range(yelp_train.shape[0]):\n",
    "    temp = yelp_train[i][0].split()\n",
    "    for j in range(len(temp)):\n",
    "        if temp[j] in pre_list_train:\n",
    "            pre_list_train[temp[j]] += 1\n",
    "        else:\n",
    "            pre_list_train[temp[j]] = 1\n",
    "            \n",
    "# sort list\n",
    "sorted_list_train = sorted(pre_list_train.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# find top 10000 words\n",
    "top_list_train = []\n",
    "\n",
    "for i in range(10000):\n",
    "    top_list_train.append(sorted_list_train[i][0])\n",
    "    \n",
    "# # scikit binary bag-of-words vectorizer\n",
    "# vectorizer = CountVectorizer(analyzer = 'word', tokenizer = None, preprocessor = None, stop_words = None, max_features = 10000)\n",
    "# vectors_train = vectorizer.fit_transform(yelp_train[:,0])\n",
    "# vectors_valid = vectorizer.transform(yelp_valid[:,0])\n",
    "# vectors_test = vectorizer.transform(yelp_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary bag-of-words representation for train, validation, test\n",
    "vectors_train = np.zeros(shape=(yelp_train.shape[0],10000),dtype=int)\n",
    "vectors_valid = np.zeros(shape=(yelp_valid.shape[0],10000),dtype=int)\n",
    "vectors_test = np.zeros(shape=(yelp_test.shape[0],10000),dtype=int)\n",
    "\n",
    "for i in range(yelp_train.shape[0]):\n",
    "    words = yelp_train[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        if top_list_train[j] in words:\n",
    "            vectors_train[i][j] = 1\n",
    "        else:\n",
    "            vectors_train[i][j] = 0\n",
    "    \n",
    "for i in range(yelp_valid.shape[0]):\n",
    "    words = yelp_valid[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        if top_list_train[j] in words:\n",
    "            vectors_valid[i][j] = 1\n",
    "        else:\n",
    "            vectors_valid[i][j] = 0\n",
    "    \n",
    "for i in range(yelp_test.shape[0]):\n",
    "    words = yelp_test[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        if top_list_train[j] in words:\n",
    "            vectors_test[i][j] = 1\n",
    "        else:\n",
    "            vectors_test[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes (y values)\n",
    "c_train = yelp_train[:,1].astype(str)\n",
    "c_valid = yelp_valid[:,1].astype(str)\n",
    "c_test = yelp_test[:,1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "\n",
    "#vocab\n",
    "f = open(\"hwk3_datasets/converted_data/yelp-vocab.txt\",\"w\",encoding='utf-8')\n",
    "for i in range(10000):\n",
    "    f.write(sorted_list_train[i][0]+\"\\t\"+str(i+1)+\"\\t\"+str(sorted_list_train[i][1])+\"\\n\")\n",
    "f.close()\n",
    "\n",
    "# datasets\n",
    "#train\n",
    "f = open(\"hwk3_datasets/converted_data/yelp-train.txt\",\"w\",encoding='utf-8')\n",
    "for i in range(yelp_train.shape[0]):\n",
    "    words = yelp_train[i][0].split(' ')\n",
    "    replaced = [(top_list_train.index(word)+1) if word in top_list_train else word for word in words]\n",
    "    for item in replaced:\n",
    "        f.write(\"%s \" %item)\n",
    "    f.write(\"\\t\" + c_train[i] + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "#validation\n",
    "f = open(\"hwk3_datasets/converted_data/yelp-valid.txt\",\"w\",encoding='utf-8')\n",
    "for i in range(yelp_valid.shape[0]):\n",
    "    words = yelp_valid[i][0].split(' ')\n",
    "    replaced = [(top_list_train.index(word)+1) if word in top_list_train else word for word in words]\n",
    "    for item in replaced:\n",
    "        if item == replaced[-1]:\n",
    "            f.write(\"%s\" %item)\n",
    "        f.write(\"%s \" %item)\n",
    "        \n",
    "    f.write(\"\\t\" + c_valid[i] + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "#test\n",
    "f = open(\"hwk3_datasets/converted_data/yelp-test.txt\",\"w\",encoding='utf-8')\n",
    "for i in range(yelp_test.shape[0]):\n",
    "    words = yelp_test[i][0].split(' ')\n",
    "    replaced = [(top_list_train.index(word)+1) if word in top_list_train else word for word in words]\n",
    "    for item in replaced:\n",
    "        if item == replaced[-1]:\n",
    "            f.write(\"%s\" %item)\n",
    "        f.write(\"%s \" %item)\n",
    "        \n",
    "    f.write(\"\\t\" + c_test[i] + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for random classifier on training dataset:  0.181391642388\n",
      "F1 score for random classifier on validation dataset:  0.196443621976\n",
      "F1 score for random classifier on test dataset:  0.188403069368\n"
     ]
    }
   ],
   "source": [
    "########### Question 2 ###########\n",
    "# random classifier\n",
    "random_results_train = np.empty(shape=(c_train.shape[0]),dtype=int)\n",
    "random_results_valid = np.empty(shape=(c_valid.shape[0]),dtype=int)\n",
    "random_results_test = np.empty(shape=(c_test.shape[0]),dtype=int)\n",
    "\n",
    "for i in range(yelp_train.shape[0]):\n",
    "    random_results_train[i] = np.random.randint(1,6)\n",
    "\n",
    "for i in range(yelp_valid.shape[0]):\n",
    "    random_results_valid[i] = np.random.randint(1,6)\n",
    "    \n",
    "for i in range(yelp_test.shape[0]):\n",
    "    random_results_test[i] = np.random.randint(1,6)\n",
    "    \n",
    "random_results_train = random_results_train.astype(str)\n",
    "random_results_valid = random_results_valid.astype(str)\n",
    "random_results_test = random_results_test.astype(str)\n",
    "\n",
    "f1_random_train = metrics.f1_score(c_train, random_results_train, average='macro')\n",
    "f1_random_valid = metrics.f1_score(c_valid, random_results_valid, average='macro')\n",
    "f1_random_test = metrics.f1_score(c_test, random_results_test, average='macro')\n",
    "print(\"F1 score for random classifier on training dataset: \", f1_random_train)\n",
    "print(\"F1 score for random classifier on validation dataset: \", f1_random_valid)\n",
    "print(\"F1 score for random classifier on test dataset: \", f1_random_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class:  4\n",
      "F1 score for majority classifier on training dataset:  0.352571428571\n",
      "F1 score for majority classifier on validation dataset:  0.356\n",
      "F1 score for majority classifier on test dataset:  0.351\n"
     ]
    }
   ],
   "source": [
    "# majority classifier\n",
    "majority_list = {}\n",
    "for i in range(yelp_train.shape[0]):\n",
    "    if yelp_train[i][1] in majority_list:\n",
    "        majority_list[yelp_train[i][1]] += 1\n",
    "    else:\n",
    "        majority_list[yelp_train[i][1]] = 1\n",
    "\n",
    "majority = max(majority_list.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "majority_results_train = np.full((yelp_train.shape[0],1),majority)\n",
    "majority_results_train = np.squeeze(majority_results_train).astype(str)\n",
    "\n",
    "majority_results_valid = np.full((yelp_valid.shape[0],1),majority)\n",
    "majority_results_valid = np.squeeze(majority_results_valid).astype(str)\n",
    "\n",
    "majority_results_test = np.full((yelp_test.shape[0],1),majority)\n",
    "majority_results_test = np.squeeze(majority_results_test).astype(str)\n",
    "\n",
    "\n",
    "f1_majority_train = metrics.f1_score(c_train, majority_results_train, average='micro')\n",
    "f1_majority_valid = metrics.f1_score(c_valid, majority_results_valid, average='micro')\n",
    "f1_majority_test = metrics.f1_score(c_test, majority_results_test, average='micro')\n",
    "print(\"Majority class: \", majority)\n",
    "print(\"F1 score for majority classifier on training dataset: \", f1_majority_train)\n",
    "print(\"F1 score for majority classifier on validation dataset: \", f1_majority_valid)\n",
    "print(\"F1 score for majority classifier on test dataset: \", f1_majority_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.001  F1_train:  0.784823208367  F1_valid:  0.357769954585\n",
      "alpha:  0.002  F1_train:  0.781606400127  F1_valid:  0.360143650098\n",
      "alpha:  0.003  F1_train:  0.779424995491  F1_valid:  0.363287823578\n",
      "alpha:  0.004  F1_train:  0.77804363117  F1_valid:  0.371852273074\n",
      "alpha:  0.005  F1_train:  0.777003654568  F1_valid:  0.375269310287\n",
      "alpha:  0.006  F1_train:  0.775676135214  F1_valid:  0.376461283229\n",
      "alpha:  0.007  F1_train:  0.773467945461  F1_valid:  0.37804555183\n",
      "alpha:  0.008  F1_train:  0.77231374774  F1_valid:  0.378195567626\n",
      "alpha:  0.009  F1_train:  0.771349809341  F1_valid:  0.376928270044\n",
      "Optimal hyperparameter for Naive Bayes:  0.008\n",
      "F1 score for Naive Bayes w/ optimal hyperparameter on training dataset:  0.77231374774\n",
      "F1 score for Naive Bayes w/ optimal hyperparameter on validation dataset:  0.378195567626\n",
      "F1 score for Naive Bayes w/ optimal hyperparameter on test dataset:  0.357689749645\n"
     ]
    }
   ],
   "source": [
    "#naive Bayes multiclass classifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "num = np.arange(0.001,0.01,0.001)  # testing multiple hyperparameters\n",
    "y_pred_list = []\n",
    "for i in range(len(num)):\n",
    "    nb_clf = BernoulliNB(alpha=num[i],binarize=None)\n",
    "    nb_clf.fit(vectors_train,c_train)\n",
    "    test = nb_clf.predict(vectors_train)\n",
    "    y_pred_list.append(nb_clf.predict(vectors_valid))\n",
    "    print(\"alpha: \", num[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid, y_pred_list[i],average=\"macro\"))\n",
    "    \n",
    "# choosing optimal hyperparameters based on F1 metric\n",
    "f1_list = []\n",
    "for i in range(len(num)):\n",
    "    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='macro'))\n",
    "\n",
    "alpha_opt = num[f1_list.index(max(f1_list))]\n",
    "print(\"Optimal hyperparameter for Naive Bayes: \", alpha_opt)\n",
    "\n",
    "# f1 metric with best hyperparameter\n",
    "nb_clf = BernoulliNB(alpha=alpha_opt)\n",
    "nb_clf.fit(vectors_train,c_train)\n",
    "y_pred_train = (nb_clf.predict(vectors_train))\n",
    "y_pred_valid = (nb_clf.predict(vectors_valid))\n",
    "y_pred_test = (nb_clf.predict(vectors_test))\n",
    "\n",
    "f1_nb_train = metrics.f1_score(c_train, y_pred_train, average='macro')\n",
    "f1_nb_valid = metrics.f1_score(c_valid,y_pred_valid, average='macro')\n",
    "f1_nb_test = metrics.f1_score(c_test, y_pred_test,average='macro')\n",
    "\n",
    "print(\"F1 score for Naive Bayes w/ optimal hyperparameter on training dataset: \", f1_nb_train)\n",
    "print(\"F1 score for Naive Bayes w/ optimal hyperparameter on validation dataset: \", f1_nb_valid)\n",
    "print(\"F1 score for Naive Bayes w/ optimal hyperparameter on test dataset: \", f1_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth:  10  F1_train:  0.423428452981  F1_valid:  0.283798756908\n",
      "Depth:  12  F1_train:  0.509317886134  F1_valid:  0.261656466917\n",
      "Depth:  14  F1_train:  0.582342605266  F1_valid:  0.280027495475\n",
      "Depth:  16  F1_train:  0.648080558544  F1_valid:  0.263341495708\n",
      "Depth:  18  F1_train:  0.700370951386  F1_valid:  0.266445699533\n",
      "Depth:  20  F1_train:  0.74569138898  F1_valid:  0.281250035928\n",
      "Depth:  22  F1_train:  0.799531736402  F1_valid:  0.26903527573\n",
      "Depth:  24  F1_train:  0.834195827204  F1_valid:  0.275214488039\n",
      "Depth:  26  F1_train:  0.867603951649  F1_valid:  0.274103368565\n",
      "Depth:  28  F1_train:  0.891560352585  F1_valid:  0.277906201393\n",
      "Depth:  30  F1_train:  0.908688951382  F1_valid:  0.276708176318\n",
      "Depth:  32  F1_train:  0.929040223038  F1_valid:  0.29498837925\n",
      "Depth:  34  F1_train:  0.938913214545  F1_valid:  0.283703989275\n",
      "Depth:  36  F1_train:  0.947706229736  F1_valid:  0.258619824271\n",
      "Depth:  38  F1_train:  0.953332483887  F1_valid:  0.274077584421\n",
      "Depth:  40  F1_train:  0.965819985694  F1_valid:  0.282582946271\n",
      "Depth:  42  F1_train:  0.980788618211  F1_valid:  0.260335601696\n",
      "Depth:  44  F1_train:  0.98500421762  F1_valid:  0.277903335004\n",
      "Depth:  46  F1_train:  0.987600436536  F1_valid:  0.276503486495\n",
      "Depth:  48  F1_train:  0.990840372703  F1_valid:  0.26425537849\n",
      "Optimal depth for Decision Tree:  32\n",
      "F1 score for Decision Tree w/ optimal depth on training dataset:  0.92818414082\n",
      "F1 score for Decision Tree w/ optimal depth on validation dataset:  0.272014137994\n",
      "F1 score for Decision Tree w/ optimal depth on testing dataset:  0.28136904953\n"
     ]
    }
   ],
   "source": [
    "# decision trees classifier \n",
    "from sklearn import tree\n",
    "depth = np.arange(10,50,2)\n",
    "y_pred_list = []\n",
    "for i in range(len(depth)):\n",
    "    dt_clf = tree.DecisionTreeClassifier(max_depth=depth[i])\n",
    "    dt_clf.fit(vectors_train,c_train)\n",
    "    y_pred_list.append(dt_clf.predict(vectors_valid))\n",
    "    test = dt_clf.predict(vectors_train)\n",
    "    print(\"Depth: \", depth[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid,y_pred_list[i], average='macro'))\n",
    "\n",
    "# choosing maximum tree depth using validation set and F1 metric\n",
    "f1_list = []\n",
    "for i in range(len(depth)):\n",
    "    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='macro'))\n",
    "\n",
    "depth_opt = depth[f1_list.index(max(f1_list))]\n",
    "print(\"Optimal depth for Decision Tree: \", depth_opt)\n",
    "\n",
    "# f1 metric for train, validation, test with optimal hyperparameter(max tree depth)\n",
    "dt_clf = tree.DecisionTreeClassifier(max_depth=depth_opt)\n",
    "dt_clf.fit(vectors_train,c_train)\n",
    "y_pred_train = dt_clf.predict(vectors_train)\n",
    "y_pred_valid = dt_clf.predict(vectors_valid)\n",
    "y_pred_test = dt_clf.predict(vectors_test)\n",
    "\n",
    "f1_dt_train = metrics.f1_score(c_train,y_pred_train,average='macro')\n",
    "f1_dt_valid = metrics.f1_score(c_valid,y_pred_valid,average='macro')\n",
    "f1_dt_test = metrics.f1_score(c_test,y_pred_test,average='macro')\n",
    "\n",
    "\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on training dataset: \", f1_dt_train)\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on validation dataset: \", f1_dt_valid)\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on testing dataset: \", f1_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.00048828125  F1_train:  0.472105621056  F1_valid:  0.328335366592\n",
      "C:  0.00244140625  F1_train:  0.644040802553  F1_valid:  0.393762700845\n",
      "C:  0.00439453125  F1_train:  0.684066141538  F1_valid:  0.412300878437\n",
      "C:  0.00634765625  F1_train:  0.712892154039  F1_valid:  0.415817051422\n",
      "C:  0.00830078125  F1_train:  0.741748944064  F1_valid:  0.414952621073\n",
      "C:  0.01025390625  F1_train:  0.760105065177  F1_valid:  0.419908391179\n",
      "C:  0.01220703125  F1_train:  0.772837733948  F1_valid:  0.422554585453\n",
      "C:  0.01416015625  F1_train:  0.782839697436  F1_valid:  0.439759463415\n",
      "C:  0.01611328125  F1_train:  0.794502051519  F1_valid:  0.438139652496\n",
      "C:  0.01806640625  F1_train:  0.801801531213  F1_valid:  0.437437104771\n",
      "C:  0.02001953125  F1_train:  0.808414022847  F1_valid:  0.442961522999\n",
      "C:  0.02197265625  F1_train:  0.816187927236  F1_valid:  0.444363499903\n",
      "C:  0.02392578125  F1_train:  0.82327808456  F1_valid:  0.453392613077\n",
      "C:  0.02587890625  F1_train:  0.831068747024  F1_valid:  0.44956500146\n",
      "C:  0.02783203125  F1_train:  0.836287299141  F1_valid:  0.440887596864\n",
      "C:  0.02978515625  F1_train:  0.841998291769  F1_valid:  0.441852790118\n",
      "C:  0.03173828125  F1_train:  0.844895276429  F1_valid:  0.440564655261\n",
      "C:  0.03369140625  F1_train:  0.848318577253  F1_valid:  0.44229271715\n",
      "C:  0.03564453125  F1_train:  0.855574914988  F1_valid:  0.439981707201\n",
      "C:  0.03759765625  F1_train:  0.857462302936  F1_valid:  0.436489901205\n",
      "C:  0.03955078125  F1_train:  0.859941607477  F1_valid:  0.443899023701\n",
      "C:  0.04150390625  F1_train:  0.86353120128  F1_valid:  0.443787510413\n",
      "C:  0.04345703125  F1_train:  0.866057974574  F1_valid:  0.441105920074\n",
      "C:  0.04541015625  F1_train:  0.868321315361  F1_valid:  0.441506842214\n",
      "C:  0.04736328125  F1_train:  0.871626836602  F1_valid:  0.440276890941\n",
      "C:  0.04931640625  F1_train:  0.874301864979  F1_valid:  0.444124622716\n",
      "C:  0.05126953125  F1_train:  0.877127867479  F1_valid:  0.441608899445\n",
      "C:  0.05322265625  F1_train:  0.880372424976  F1_valid:  0.441340678526\n",
      "C:  0.05517578125  F1_train:  0.881752913827  F1_valid:  0.441344129182\n",
      "C:  0.05712890625  F1_train:  0.883504829075  F1_valid:  0.442688142255\n",
      "C:  0.05908203125  F1_train:  0.887095409218  F1_valid:  0.442106987204\n",
      "C:  0.06103515625  F1_train:  0.887913623418  F1_valid:  0.44351541937\n",
      "C:  0.06298828125  F1_train:  0.890032576396  F1_valid:  0.442142023721\n",
      "C:  0.06494140625  F1_train:  0.891567410426  F1_valid:  0.441642252049\n",
      "C:  0.06689453125  F1_train:  0.893216989512  F1_valid:  0.437290836662\n",
      "C:  0.06884765625  F1_train:  0.895795965077  F1_valid:  0.437290836662\n",
      "C:  0.07080078125  F1_train:  0.897242032538  F1_valid:  0.439602493406\n",
      "C:  0.07275390625  F1_train:  0.898866360802  F1_valid:  0.436509285804\n",
      "C:  0.07470703125  F1_train:  0.90189830238  F1_valid:  0.440039422585\n",
      "C:  0.07666015625  F1_train:  0.903225742053  F1_valid:  0.431280410253\n",
      "C:  0.07861328125  F1_train:  0.905540939785  F1_valid:  0.433401354013\n",
      "C:  0.08056640625  F1_train:  0.905911267379  F1_valid:  0.429822300109\n",
      "C:  0.08251953125  F1_train:  0.908814942134  F1_valid:  0.427580060391\n",
      "C:  0.08447265625  F1_train:  0.910133002291  F1_valid:  0.43029335238\n",
      "C:  0.08642578125  F1_train:  0.912292423096  F1_valid:  0.427324541715\n",
      "C:  0.08837890625  F1_train:  0.913332255825  F1_valid:  0.430931891524\n",
      "C:  0.09033203125  F1_train:  0.914868321218  F1_valid:  0.432887886483\n",
      "C:  0.09228515625  F1_train:  0.916447287328  F1_valid:  0.435006080636\n",
      "C:  0.09423828125  F1_train:  0.91669812171  F1_valid:  0.435557522675\n",
      "C:  0.09619140625  F1_train:  0.919131934281  F1_valid:  0.431043692818\n",
      "C:  0.09814453125  F1_train:  0.919376433582  F1_valid:  0.431228125534\n",
      "Optimal C for Linear SVM:  0.02392578125\n",
      "F1 score for Linear SVM w/ optimal depth on training dataset:  0.823567236111\n",
      "F1 score for Linear SVM w/ optimal depth on validation dataset:  0.453392613077\n",
      "F1 score for Linear SVM w/ optimal depth on testing dataset:  0.442735739913\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "c = np.arange(2**-11,0.1,2**-9)\n",
    "#c = [2**-7, 2**-5, 2**-3, 2**-1, 2**1, 2**3, 2**5, 2**7]\n",
    "y_pred_list = []\n",
    "for i in range(len(c)):\n",
    "    svm_clf = LinearSVC(C=c[i], multi_class=\"ovr\", loss='hinge')\n",
    "    svm_clf.fit(vectors_train,c_train)\n",
    "    y_pred_list.append(svm_clf.predict(vectors_valid))\n",
    "    test = svm_clf.predict(vectors_train)\n",
    "    print(\"C: \", c[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid,y_pred_list[i],average='macro'))\n",
    "    \n",
    "f1_list = []\n",
    "for i in range(len(c)):\n",
    "    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='macro'))\n",
    "\n",
    "c_opt = c[f1_list.index(max(f1_list))]\n",
    "print(\"Optimal C for Linear SVM: \", c_opt)\n",
    "\n",
    "\n",
    "# f1 metric for train, validation, test dataset with optimal c\n",
    "svm_clf=LinearSVC(C=c_opt, multi_class='ovr', loss='hinge')\n",
    "svm_clf.fit(vectors_train,c_train)\n",
    "\n",
    "y_pred_train = svm_clf.predict(vectors_train)\n",
    "y_pred_valid = svm_clf.predict(vectors_valid)\n",
    "y_pred_test = svm_clf.predict(vectors_test)\n",
    "\n",
    "f1_svm_train = metrics.f1_score(c_train,y_pred_train,average='macro')\n",
    "f1_svm_valid = metrics.f1_score(c_valid,y_pred_valid,average='macro')\n",
    "f1_svm_test = metrics.f1_score(c_test,y_pred_test,average='macro')\n",
    "\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on training dataset: \", f1_svm_train)\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on validation dataset: \", f1_svm_valid)\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on testing dataset: \", f1_svm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Bag-of-Words\n",
    "## IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary bag-of-words\n",
    "#IMDB\n",
    "\n",
    "data4 = pd.read_csv(\"hwk3_datasets/IMDB-train.txt\", sep=\"\\t\", header=None)\n",
    "data5 = pd.read_csv(\"hwk3_datasets/IMDB-valid.txt\", sep=\"\\t\",  header=None)\n",
    "data6 = pd.read_csv(\"hwk3_datasets/IMDB-test.txt\", sep=\"\\t\",  header=None)\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "for i in range(data4[0].count()):\n",
    "    temp = data4[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data4[0][i] = temp\n",
    "\n",
    "for i in range(data5[0].count()):\n",
    "    temp = data5[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data5[0][i] = temp\n",
    "\n",
    "for i in range(data6[0].count()):\n",
    "    temp = data6[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data6[0][i] = temp\n",
    "\n",
    "imdb_train = data4.values\n",
    "imdb_valid = data5.values\n",
    "imdb_test = data6.values\n",
    "\n",
    "# generating top 10000 words\n",
    "pre_list_train = {}\n",
    "\n",
    "\n",
    "for i in range(imdb_train.shape[0]):\n",
    "    temp = imdb_train[i][0].split()\n",
    "    for j in range(len(temp)):\n",
    "        if temp[j] in pre_list_train:\n",
    "            pre_list_train[temp[j]] += 1\n",
    "        else:\n",
    "            pre_list_train[temp[j]] = 1\n",
    "            \n",
    "# sort list\n",
    "sorted_list_train = sorted(pre_list_train.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# find top 10000 words\n",
    "top_list_train = []\n",
    "\n",
    "for i in range(10000):\n",
    "    top_list_train.append(sorted_list_train[i][0])\n",
    "    \n",
    "# # scikit binary bag-of-words vectorizer\n",
    "# vectorizer = CountVectorizer(analyzer = 'word', tokenizer = None, preprocessor = None, stop_words = None, max_features = 10000)\n",
    "# vectors_train = vectorizer.fit_transform(imdb_train[:,0])\n",
    "# vectors_valid = vectorizer.transform(imdb_valid[:,0])\n",
    "# vectors_test = vectorizer.transform(imdb_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary bag-of-words representation for train, validation, test\n",
    "vectors_train = np.zeros(shape=(imdb_train.shape[0],10000),dtype=int)\n",
    "vectors_valid = np.zeros(shape=(imdb_valid.shape[0],10000),dtype=int)\n",
    "vectors_test = np.zeros(shape=(imdb_test.shape[0],10000),dtype=int)\n",
    "\n",
    "for i in range(imdb_train.shape[0]):\n",
    "    words = imdb_train[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        if top_list_train[j] in words:\n",
    "            vectors_train[i][j] = 1\n",
    "        else:\n",
    "            vectors_train[i][j] = 0\n",
    "    \n",
    "for i in range(imdb_valid.shape[0]):\n",
    "    words = imdb_valid[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        if top_list_train[j] in words:\n",
    "            vectors_valid[i][j] = 1\n",
    "        else:\n",
    "            vectors_valid[i][j] = 0\n",
    "    \n",
    "for i in range(imdb_test.shape[0]):\n",
    "    words = imdb_test[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        if top_list_train[j] in words:\n",
    "            vectors_test[i][j] = 1\n",
    "        else:\n",
    "            vectors_test[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes (y values)\n",
    "c_train = imdb_train[:,1].astype(str)\n",
    "c_valid = imdb_valid[:,1].astype(str)\n",
    "c_test = imdb_test[:,1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset\n",
    "\n",
    "#vocab\n",
    "f = open(\"hwk3_datasets/converted_data/IMDB-vocab.txt\",\"w\",encoding='utf-8')\n",
    "for i in range(10000):\n",
    "    f.write(sorted_list_train[i][0]+\"\\t\"+str(i+1)+\"\\t\"+str(sorted_list_train[i][1])+\"\\n\")\n",
    "f.close()\n",
    "\n",
    "# datasets\n",
    "#train\n",
    "f = open(\"hwk3_datasets/converted_data/IMDB-train.txt\",\"w\",encoding='utf-8')\n",
    "for i in range(imdb_train.shape[0]):\n",
    "    words = imdb_train[i][0].split(' ')\n",
    "    replaced = [(top_list_train.index(word)+1) if word in top_list_train else word for word in words]\n",
    "    for item in replaced:\n",
    "        f.write(\"%s \" %item)\n",
    "    f.write(\"\\t\" + c_train[i] + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "#validation\n",
    "f = open(\"hwk3_datasets/converted_data/IMDB-valid.txt\",\"w\",encoding='utf-8')\n",
    "for i in range(imdb_valid.shape[0]):\n",
    "    words = imdb_valid[i][0].split(' ')\n",
    "    replaced = [(top_list_train.index(word)+1) if word in top_list_train else word for word in words]\n",
    "    for item in replaced:\n",
    "        if item == replaced[-1]:\n",
    "            f.write(\"%s\" %item)\n",
    "        f.write(\"%s \" %item)\n",
    "        \n",
    "    f.write(\"\\t\" + c_valid[i] + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "#test\n",
    "f = open(\"hwk3_datasets/converted_data/IMDB-test.txt\",\"w\",encoding='utf-8')\n",
    "for i in range(imdb_test.shape[0]):\n",
    "    words = imdb_test[i][0].split(' ')\n",
    "    replaced = [(top_list_train.index(word)+1) if word in top_list_train else word for word in words]\n",
    "    for item in replaced:\n",
    "        if item == replaced[-1]:\n",
    "            f.write(\"%s\" %item)\n",
    "        f.write(\"%s \" %item)\n",
    "        \n",
    "    f.write(\"\\t\" + c_test[i] + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for random classifier on training dataset:  0.500799991125\n",
      "F1 score for random classifier on validation dataset:  0.509285155876\n",
      "F1 score for random classifier on test dataset:  0.497759971071\n"
     ]
    }
   ],
   "source": [
    "# random classifier\n",
    "random_results_train = np.empty(shape=(c_train.shape[0]),dtype=int)\n",
    "random_results_valid = np.empty(shape=(c_valid.shape[0]),dtype=int)\n",
    "random_results_test = np.empty(shape=(c_test.shape[0]),dtype=int)\n",
    "\n",
    "for i in range(imdb_train.shape[0]):\n",
    "    random_results_train[i] = np.random.randint(0,2)\n",
    "\n",
    "for i in range(imdb_valid.shape[0]):\n",
    "    random_results_valid[i] = np.random.randint(0,2)\n",
    "    \n",
    "for i in range(imdb_test.shape[0]):\n",
    "    random_results_test[i] = np.random.randint(0,2)\n",
    "    \n",
    "random_results_train = random_results_train.astype(str)\n",
    "random_results_valid = random_results_valid.astype(str)\n",
    "random_results_test = random_results_test.astype(str)\n",
    "\n",
    "f1_random_train = metrics.f1_score(c_train, random_results_train, average='macro')\n",
    "f1_random_valid = metrics.f1_score(c_valid, random_results_valid, average='macro')\n",
    "f1_random_test = metrics.f1_score(c_test, random_results_test, average='macro')\n",
    "print(\"F1 score for random classifier on training dataset: \", f1_random_train)\n",
    "print(\"F1 score for random classifier on validation dataset: \", f1_random_valid)\n",
    "print(\"F1 score for random classifier on test dataset: \", f1_random_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.001  F1_train:  0.872771118478  F1_valid:  0.843077024907\n",
      "alpha:  0.002  F1_train:  0.872771118478  F1_valid:  0.843077024907\n",
      "alpha:  0.003  F1_train:  0.872771118478  F1_valid:  0.843175886724\n",
      "alpha:  0.004  F1_train:  0.872771118478  F1_valid:  0.843075480544\n",
      "alpha:  0.005  F1_train:  0.872771118478  F1_valid:  0.843075480544\n",
      "alpha:  0.006  F1_train:  0.872771118478  F1_valid:  0.843175886724\n",
      "alpha:  0.007  F1_train:  0.872771118478  F1_valid:  0.843175102479\n",
      "alpha:  0.008  F1_train:  0.872771118478  F1_valid:  0.843075480544\n",
      "alpha:  0.009  F1_train:  0.872704180328  F1_valid:  0.843075480544\n",
      "Optimal hyperparameter for Naive Bayes:  0.003\n",
      "F1 score for Naive Bayes w/ optimal hyperparameter on training dataset:  0.872771118478\n",
      "F1 score for Naive Bayes w/ optimal hyperparameter on validation dataset:  0.843175886724\n",
      "F1 score for Naive Bayes w/ optimal hyperparameter on test dataset:  0.835259920588\n"
     ]
    }
   ],
   "source": [
    "#naive Bayes multiclass classifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "num = np.arange(0.001,0.01,0.001)  # testing multiple hyperparameters\n",
    "y_pred_list = []\n",
    "for i in range(len(num)):\n",
    "    nb_clf = BernoulliNB(alpha=num[i],binarize=None)\n",
    "    nb_clf.fit(vectors_train,c_train)\n",
    "    test = nb_clf.predict(vectors_train)\n",
    "    y_pred_list.append(nb_clf.predict(vectors_valid))\n",
    "    print(\"alpha: \", num[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid, y_pred_list[i],average=\"macro\"))\n",
    "    \n",
    "# choosing optimal hyperparameters based on F1 metric\n",
    "f1_list = []\n",
    "for i in range(len(num)):\n",
    "    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='macro'))\n",
    "\n",
    "alpha_opt = num[f1_list.index(max(f1_list))]\n",
    "print(\"Optimal hyperparameter for Naive Bayes: \", alpha_opt)\n",
    "\n",
    "# f1 metric with best hyperparameter\n",
    "nb_clf = BernoulliNB(alpha=alpha_opt)\n",
    "nb_clf.fit(vectors_train,c_train)\n",
    "y_pred_train = (nb_clf.predict(vectors_train))\n",
    "y_pred_valid = (nb_clf.predict(vectors_valid))\n",
    "y_pred_test = (nb_clf.predict(vectors_test))\n",
    "\n",
    "f1_nb_train = metrics.f1_score(c_train, y_pred_train, average='macro')\n",
    "f1_nb_valid = metrics.f1_score(c_valid,y_pred_valid, average='macro')\n",
    "f1_nb_test = metrics.f1_score(c_test, y_pred_test,average='macro')\n",
    "\n",
    "print(\"F1 score for Naive Bayes w/ optimal hyperparameter on training dataset: \", f1_nb_train)\n",
    "print(\"F1 score for Naive Bayes w/ optimal hyperparameter on validation dataset: \", f1_nb_valid)\n",
    "print(\"F1 score for Naive Bayes w/ optimal hyperparameter on test dataset: \", f1_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth:  10  F1_train:  0.760842843323  F1_valid:  0.711618102202\n",
      "Depth:  12  F1_train:  0.784775599482  F1_valid:  0.711707475031\n",
      "Depth:  14  F1_train:  0.813524204257  F1_valid:  0.716593294035\n",
      "Depth:  16  F1_train:  0.840843998549  F1_valid:  0.720396710935\n",
      "Depth:  18  F1_train:  0.858351113688  F1_valid:  0.715001355296\n",
      "Depth:  20  F1_train:  0.875782268953  F1_valid:  0.71496063426\n",
      "Depth:  22  F1_train:  0.89029714748  F1_valid:  0.715170898613\n",
      "Depth:  24  F1_train:  0.904044655242  F1_valid:  0.712266288293\n",
      "Depth:  26  F1_train:  0.917405559996  F1_valid:  0.711291087344\n",
      "Depth:  28  F1_train:  0.92749226205  F1_valid:  0.709602748865\n",
      "Depth:  30  F1_train:  0.937768588626  F1_valid:  0.707453211724\n",
      "Depth:  32  F1_train:  0.948299627218  F1_valid:  0.706237373274\n",
      "Depth:  34  F1_train:  0.956181883643  F1_valid:  0.709596264882\n",
      "Depth:  36  F1_train:  0.964387591054  F1_valid:  0.702189068406\n",
      "Depth:  38  F1_train:  0.969055729724  F1_valid:  0.702159750005\n",
      "Depth:  40  F1_train:  0.972124031928  F1_valid:  0.70034559108\n",
      "Depth:  42  F1_train:  0.974857968529  F1_valid:  0.701535172799\n",
      "Depth:  44  F1_train:  0.979796002213  F1_valid:  0.699934273603\n",
      "Depth:  46  F1_train:  0.98193015296  F1_valid:  0.701362538917\n",
      "Depth:  48  F1_train:  0.983063833735  F1_valid:  0.699139334455\n",
      "Optimal depth for Decision Tree:  16\n",
      "F1 score for Decision Tree w/ optimal depth on training dataset:  0.840721212567\n",
      "F1 score for Decision Tree w/ optimal depth on validation dataset:  0.718421166933\n",
      "F1 score for Decision Tree w/ optimal depth on testing dataset:  0.726645986638\n"
     ]
    }
   ],
   "source": [
    "# decision trees classifier 441700\n",
    "from sklearn import tree\n",
    "depth = np.arange(10,50,2)\n",
    "y_pred_list = []\n",
    "for i in range(len(depth)):\n",
    "    dt_clf = tree.DecisionTreeClassifier(max_depth=depth[i])\n",
    "    dt_clf.fit(vectors_train,c_train)\n",
    "    y_pred_list.append(dt_clf.predict(vectors_valid))\n",
    "    test = dt_clf.predict(vectors_train)\n",
    "    print(\"Depth: \", depth[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid,y_pred_list[i], average='macro'))\n",
    "\n",
    "# choosing maximum tree depth using validation set and F1 metric\n",
    "f1_list = []\n",
    "for i in range(len(depth)):\n",
    "    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='macro'))\n",
    "\n",
    "depth_opt = depth[f1_list.index(max(f1_list))]\n",
    "print(\"Optimal depth for Decision Tree: \", depth_opt)\n",
    "\n",
    "# f1 metric for train, validation, test with optimal hyperparameter(max tree depth)\n",
    "dt_clf = tree.DecisionTreeClassifier(max_depth=depth_opt)\n",
    "dt_clf.fit(vectors_train,c_train)\n",
    "y_pred_train = dt_clf.predict(vectors_train)\n",
    "y_pred_valid = dt_clf.predict(vectors_valid)\n",
    "y_pred_test = dt_clf.predict(vectors_test)\n",
    "\n",
    "f1_dt_train = metrics.f1_score(c_train,y_pred_train,average='macro')\n",
    "f1_dt_valid = metrics.f1_score(c_valid,y_pred_valid,average='macro')\n",
    "f1_dt_test = metrics.f1_score(c_test,y_pred_test,average='macro')\n",
    "\n",
    "\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on training dataset: \", f1_dt_train)\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on validation dataset: \", f1_dt_valid)\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on testing dataset: \", f1_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.00048828125  F1_train:  0.85315962003  F1_valid:  0.834230251778\n",
      "C:  0.00244140625  F1_train:  0.894304673928  F1_valid:  0.863657285191\n",
      "C:  0.00439453125  F1_train:  0.909449255167  F1_valid:  0.872372044373\n",
      "C:  0.00634765625  F1_train:  0.919256417256  F1_valid:  0.873680889182\n",
      "C:  0.00830078125  F1_train:  0.925256493245  F1_valid:  0.875385998371\n",
      "C:  0.01025390625  F1_train:  0.930325306499  F1_valid:  0.876391278169\n",
      "C:  0.01220703125  F1_train:  0.935994738483  F1_valid:  0.87629147772\n",
      "C:  0.01416015625  F1_train:  0.940529269236  F1_valid:  0.876092266918\n",
      "C:  0.01611328125  F1_train:  0.944864361017  F1_valid:  0.876892700968\n",
      "C:  0.01806640625  F1_train:  0.947598356684  F1_valid:  0.876193581875\n",
      "C:  0.02001953125  F1_train:  0.948864866483  F1_valid:  0.876294446858\n",
      "C:  0.02197265625  F1_train:  0.950664968665  F1_valid:  0.876794953521\n",
      "C:  0.02392578125  F1_train:  0.952865292219  F1_valid:  0.875896513933\n",
      "C:  0.02587890625  F1_train:  0.955065451636  F1_valid:  0.876498309262\n",
      "C:  0.02783203125  F1_train:  0.9566657761  F1_valid:  0.87639928806\n",
      "C:  0.02978515625  F1_train:  0.958199396399  F1_valid:  0.876199163106\n",
      "C:  0.03173828125  F1_train:  0.959666084245  F1_valid:  0.875299549831\n",
      "C:  0.03369140625  F1_train:  0.960999355016  F1_valid:  0.874799754608\n",
      "C:  0.03564453125  F1_train:  0.962132767176  F1_valid:  0.8741998742\n",
      "C:  0.03759765625  F1_train:  0.963066288465  F1_valid:  0.873499715374\n",
      "C:  0.03955078125  F1_train:  0.963999631356  F1_valid:  0.873299785877\n",
      "C:  0.04150390625  F1_train:  0.964799749687  F1_valid:  0.872199488798\n",
      "C:  0.04345703125  F1_train:  0.965933103041  F1_valid:  0.87209920062\n",
      "C:  0.04541015625  F1_train:  0.967133111153  F1_valid:  0.872099323405\n",
      "C:  0.04736328125  F1_train:  0.968333119265  F1_valid:  0.871799584631\n",
      "C:  0.04931640625  F1_train:  0.969199780976  F1_valid:  0.87029905448\n",
      "C:  0.05126953125  F1_train:  0.970133120947  F1_valid:  0.870099531059\n",
      "C:  0.05322265625  F1_train:  0.970933165908  F1_valid:  0.870099427138\n",
      "C:  0.05517578125  F1_train:  0.971666475132  F1_valid:  0.869499706374\n",
      "C:  0.05712890625  F1_train:  0.972266488679  F1_valid:  0.869599478398\n",
      "C:  0.05908203125  F1_train:  0.972866483244  F1_valid:  0.868999114434\n",
      "C:  0.06103515625  F1_train:  0.973466458644  F1_valid:  0.868799364989\n",
      "C:  0.06298828125  F1_train:  0.974266501515  F1_valid:  0.868499525283\n",
      "C:  0.06494140625  F1_train:  0.974399817954  F1_valid:  0.867499299071\n",
      "C:  0.06689453125  F1_train:  0.97506652305  F1_valid:  0.866399567135\n",
      "C:  0.06884765625  F1_train:  0.975599859455  F1_valid:  0.866399353373\n",
      "C:  0.07080078125  F1_train:  0.976333173346  F1_valid:  0.86529915812\n",
      "C:  0.07275390625  F1_train:  0.976933185296  F1_valid:  0.865199088746\n",
      "C:  0.07470703125  F1_train:  0.977466536874  F1_valid:  0.865298705521\n",
      "C:  0.07666015625  F1_train:  0.978066560509  F1_valid:  0.865298533101\n",
      "C:  0.07861328125  F1_train:  0.978666529753  F1_valid:  0.864898701677\n",
      "C:  0.08056640625  F1_train:  0.979066517806  F1_valid:  0.864398936888\n",
      "C:  0.08251953125  F1_train:  0.979399860743  F1_valid:  0.864298858753\n",
      "C:  0.08447265625  F1_train:  0.979733216597  F1_valid:  0.864198777789\n",
      "C:  0.08642578125  F1_train:  0.980133218901  F1_valid:  0.864499012198\n",
      "C:  0.08837890625  F1_train:  0.980333238146  F1_valid:  0.864199081986\n",
      "C:  0.09033203125  F1_train:  0.980799942314  F1_valid:  0.863999341757\n",
      "C:  0.09228515625  F1_train:  0.981066618197  F1_valid:  0.863399453598\n",
      "C:  0.09423828125  F1_train:  0.981666643118  F1_valid:  0.862799451198\n",
      "C:  0.09619140625  F1_train:  0.982199971441  F1_valid:  0.862499503623\n",
      "C:  0.09814453125  F1_train:  0.98253331346  F1_valid:  0.862399449598\n",
      "Optimal C for Linear SVM:  0.01611328125\n",
      "F1 score for Linear SVM w/ optimal depth on training dataset:  0.944864361017\n",
      "F1 score for Linear SVM w/ optimal depth on validation dataset:  0.876892700968\n",
      "F1 score for Linear SVM w/ optimal depth on testing dataset:  0.872273304873\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "c = np.arange(2**-11,0.1,2**-9)\n",
    "#c = [2**-7, 2**-5, 2**-3, 2**-1, 2**1, 2**3, 2**5, 2**7]\n",
    "y_pred_list = []\n",
    "for i in range(len(c)):\n",
    "    svm_clf = LinearSVC(C=c[i], multi_class=\"ovr\", loss='hinge')\n",
    "    svm_clf.fit(vectors_train,c_train)\n",
    "    y_pred_list.append(svm_clf.predict(vectors_valid))\n",
    "    test = svm_clf.predict(vectors_train)\n",
    "    print(\"C: \", c[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid,y_pred_list[i],average='macro'))\n",
    "    \n",
    "f1_list = []\n",
    "for i in range(len(c)):\n",
    "    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='macro'))\n",
    "\n",
    "c_opt = c[f1_list.index(max(f1_list))]\n",
    "print(\"Optimal C for Linear SVM: \", c_opt)\n",
    "\n",
    "\n",
    "# f1 metric for train, validation, test dataset with optimal c\n",
    "svm_clf=LinearSVC(C=c_opt, multi_class='ovr', loss='hinge')\n",
    "svm_clf.fit(vectors_train,c_train)\n",
    "\n",
    "y_pred_train = svm_clf.predict(vectors_train)\n",
    "y_pred_valid = svm_clf.predict(vectors_valid)\n",
    "y_pred_test = svm_clf.predict(vectors_test)\n",
    "\n",
    "f1_svm_train = metrics.f1_score(c_train,y_pred_train,average='macro')\n",
    "f1_svm_valid = metrics.f1_score(c_valid,y_pred_valid,average='macro')\n",
    "f1_svm_test = metrics.f1_score(c_test,y_pred_test,average='macro')\n",
    "\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on training dataset: \", f1_svm_train)\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on validation dataset: \", f1_svm_valid)\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on testing dataset: \", f1_svm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Bag-of-Words\n",
    "## Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## frequency bag-of-words\n",
    "# yelp\n",
    "data7 = pd.read_csv(\"hwk3_datasets/yelp-train.txt\", sep=\"\\t\", header=None)\n",
    "data8 = pd.read_csv(\"hwk3_datasets/yelp-valid.txt\", sep=\"\\t\",  header=None)\n",
    "data9 = pd.read_csv(\"hwk3_datasets/yelp-test.txt\", sep=\"\\t\",  header=None)\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "for i in range(data7[0].count()):\n",
    "    temp = data7[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data7[0][i] = temp\n",
    "\n",
    "for i in range(data8[0].count()):\n",
    "    temp = data8[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data8[0][i] = temp\n",
    "\n",
    "for i in range(data9[0].count()):\n",
    "    temp = data9[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data9[0][i] = temp\n",
    "\n",
    "yelp_train = data7.values\n",
    "yelp_valid = data8.values\n",
    "yelp_test = data9.values\n",
    "\n",
    "# generating top 10000 words\n",
    "pre_list_train = {}\n",
    "\n",
    "for i in range(yelp_train.shape[0]):\n",
    "    temp = yelp_train[i][0].split()\n",
    "    for j in range(len(temp)):\n",
    "        if temp[j] in pre_list_train:\n",
    "            pre_list_train[temp[j]] += 1\n",
    "        else:\n",
    "            pre_list_train[temp[j]] = 1\n",
    "            \n",
    "# sort list\n",
    "sorted_list_train = sorted(pre_list_train.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# find top 10000 words\n",
    "top_list_train = []\n",
    "\n",
    "for i in range(10000):\n",
    "    top_list_train.append(sorted_list_train[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create frequency bag-of-words representation for train, validation, test\n",
    "vectors_train = np.zeros(shape=(yelp_train.shape[0],10000))\n",
    "vectors_valid = np.zeros(shape=(yelp_valid.shape[0],10000))\n",
    "vectors_test = np.zeros(shape=(yelp_test.shape[0],10000))\n",
    "\n",
    "for i in range(yelp_train.shape[0]):\n",
    "    words = yelp_train[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        vectors_train[i][j] = words.count(top_list_train[j])\n",
    "        \n",
    "    if (np.sum(vectors_train[i]) == 0):\n",
    "        continue\n",
    "    vectors_train[i] = vectors_train[i]/(np.sum(vectors_train[i]))\n",
    "    \n",
    "    \n",
    "for i in range(yelp_valid.shape[0]):\n",
    "    words = yelp_valid[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        vectors_valid[i][j] = words.count(top_list_train[j])\n",
    "\n",
    "    if (np.sum(vectors_valid[i]) == 0):\n",
    "        continue\n",
    "    vectors_valid[i] = vectors_valid[i]/(np.sum(vectors_valid[i]))\n",
    "    \n",
    "    \n",
    "for i in range(yelp_test.shape[0]):\n",
    "    words = yelp_test[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        vectors_test[i][j] = words.count(top_list_train[j])\n",
    "\n",
    "    if (np.sum(vectors_test[i]) == 0):\n",
    "        continue\n",
    "    vectors_test[i] = vectors_test[i]/(np.sum(vectors_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classes (y values)\n",
    "c_train = yelp_train[:,1].astype(str)\n",
    "c_valid = yelp_valid[:,1].astype(str)\n",
    "c_test = yelp_test[:,1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for random classifier on training dataset:  0.178485535888\n",
      "F1 score for random classifier on validation dataset:  0.191607412581\n",
      "F1 score for random classifier on test dataset:  0.185708757633\n"
     ]
    }
   ],
   "source": [
    "# random classifier\n",
    "random_results_train = np.empty(shape=(c_train.shape[0]),dtype=int)\n",
    "random_results_valid = np.empty(shape=(c_valid.shape[0]),dtype=int)\n",
    "random_results_test = np.empty(shape=(c_test.shape[0]),dtype=int)\n",
    "\n",
    "for i in range(yelp_train.shape[0]):\n",
    "    random_results_train[i] = np.random.randint(1,6)\n",
    "\n",
    "for i in range(yelp_valid.shape[0]):\n",
    "    random_results_valid[i] = np.random.randint(1,6)\n",
    "    \n",
    "for i in range(yelp_test.shape[0]):\n",
    "    random_results_test[i] = np.random.randint(1,6)\n",
    "    \n",
    "random_results_train = random_results_train.astype(str)\n",
    "random_results_valid = random_results_valid.astype(str)\n",
    "random_results_test = random_results_test.astype(str)\n",
    "\n",
    "f1_random_train = metrics.f1_score(c_train, random_results_train, average='macro')\n",
    "f1_random_valid = metrics.f1_score(c_valid, random_results_valid, average='macro')\n",
    "f1_random_test = metrics.f1_score(c_test, random_results_test, average='macro')\n",
    "print(\"F1 score for random classifier on training dataset: \", f1_random_train)\n",
    "print(\"F1 score for random classifier on validation dataset: \", f1_random_valid)\n",
    "print(\"F1 score for random classifier on test dataset: \", f1_random_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class:  4\n",
      "F1 score for majority classifier on training dataset:  0.352571428571\n",
      "F1 score for majority classifier on validation dataset:  0.356\n",
      "F1 score for majority classifier on test dataset:  0.351\n"
     ]
    }
   ],
   "source": [
    "# majority classifier\n",
    "majority_list = {}\n",
    "for i in range(yelp_train.shape[0]):\n",
    "    if yelp_train[i][1] in majority_list:\n",
    "        majority_list[yelp_train[i][1]] += 1\n",
    "    else:\n",
    "        majority_list[yelp_train[i][1]] = 1\n",
    "\n",
    "majority = max(majority_list.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "majority_results_train = np.full((yelp_train.shape[0],1),majority)\n",
    "majority_results_train = np.squeeze(majority_results_train).astype(str)\n",
    "\n",
    "majority_results_valid = np.full((yelp_valid.shape[0],1),majority)\n",
    "majority_results_valid = np.squeeze(majority_results_valid).astype(str)\n",
    "\n",
    "majority_results_test = np.full((yelp_test.shape[0],1),majority)\n",
    "majority_results_test = np.squeeze(majority_results_test).astype(str)\n",
    "\n",
    "\n",
    "f1_majority_train = metrics.f1_score(c_train, majority_results_train, average='micro')\n",
    "f1_majority_valid = metrics.f1_score(c_valid, majority_results_valid, average='micro')\n",
    "f1_majority_test = metrics.f1_score(c_test, majority_results_test, average='micro')\n",
    "print(\"Majority class: \", majority)\n",
    "print(\"F1 score for majority classifier on training dataset: \", f1_majority_train)\n",
    "print(\"F1 score for majority classifier on validation dataset: \", f1_majority_valid)\n",
    "print(\"F1 score for majority classifier on test dataset: \", f1_majority_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on training dataset:  0.787889954289\n",
      "F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on validation dataset:  0.245619015208\n",
      "F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on test dataset:  0.247784668019\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Bayes multiclass classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#num = np.arange(0.001,1,0.001)  # testing multiple hyperparameters\n",
    "#y_pred_list = []\n",
    "#for i in range(len(num)):\n",
    "    #nb_clf = GaussianNB()\n",
    "    #nb_clf.fit(vectors_train,c_train)\n",
    "    #test = nb_clf.predict(vectors_train)\n",
    "    #y_pred_list.append(nb_clf.predict(vectors_valid))\n",
    "    #print(\"alpha: \", num[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid, y_pred_list[i],average=\"macro\"))\n",
    "    \n",
    "# choosing optimal hyperparameters based on F1 metric\n",
    "#f1_list = []\n",
    "#for i in range(len(num)):\n",
    "#    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='micro'))\n",
    "\n",
    "#alpha_opt = num[f1_list.index(max(f1_list))]\n",
    "#print(\"Optimal hyperparameter for Naive Bayes: \", alpha_opt)\n",
    "\n",
    "# f1 metric with best hyperparameter\n",
    "gs_clf = GaussianNB()\n",
    "gs_clf.fit(vectors_train,c_train)\n",
    "y_pred_train = (gs_clf.predict(vectors_train))\n",
    "y_pred_valid = (gs_clf.predict(vectors_valid))\n",
    "y_pred_test = (gs_clf.predict(vectors_test))\n",
    "\n",
    "f1_nb_train = metrics.f1_score(c_train, y_pred_train, average='macro')\n",
    "f1_nb_valid = metrics.f1_score(c_valid,y_pred_valid, average='macro')\n",
    "f1_nb_test = metrics.f1_score(c_test, y_pred_test,average='macro')\n",
    "\n",
    "print(\"F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on training dataset: \", f1_nb_train)\n",
    "print(\"F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on validation dataset: \", f1_nb_valid)\n",
    "print(\"F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on test dataset: \", f1_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth:  10  F1_train:  0.436416839611  F1_valid:  0.303011210633\n",
      "Depth:  12  F1_train:  0.511334183231  F1_valid:  0.306516888356\n",
      "Depth:  14  F1_train:  0.586155122748  F1_valid:  0.294358449115\n",
      "Depth:  16  F1_train:  0.662002668151  F1_valid:  0.294218129108\n",
      "Depth:  18  F1_train:  0.72268986416  F1_valid:  0.322305765646\n",
      "Depth:  20  F1_train:  0.766843169788  F1_valid:  0.30485241354\n",
      "Depth:  22  F1_train:  0.821854461205  F1_valid:  0.30273731443\n",
      "Depth:  24  F1_train:  0.866962028248  F1_valid:  0.294152794107\n",
      "Depth:  26  F1_train:  0.900996337975  F1_valid:  0.300671039523\n",
      "Depth:  28  F1_train:  0.924322040227  F1_valid:  0.298544799589\n",
      "Depth:  30  F1_train:  0.946484377066  F1_valid:  0.296849751147\n",
      "Depth:  32  F1_train:  0.966239144137  F1_valid:  0.300595007861\n",
      "Depth:  34  F1_train:  0.982672063495  F1_valid:  0.310778341297\n",
      "Depth:  36  F1_train:  0.990408964902  F1_valid:  0.308291940038\n",
      "Depth:  38  F1_train:  0.993350044691  F1_valid:  0.314653308972\n",
      "Depth:  40  F1_train:  0.99693283952  F1_valid:  0.2902175851\n",
      "Depth:  42  F1_train:  0.996769177315  F1_valid:  0.29934459479\n",
      "Depth:  44  F1_train:  0.997956549776  F1_valid:  0.30330395046\n",
      "Depth:  46  F1_train:  0.998534997111  F1_valid:  0.305252499005\n",
      "Depth:  48  F1_train:  0.998631853211  F1_valid:  0.29767086543\n",
      "Optimal depth for Decision Tree:  18\n",
      "F1 score for Decision Tree w/ optimal depth on training dataset:  0.724307758517\n",
      "F1 score for Decision Tree w/ optimal depth on validation dataset:  0.311966116279\n",
      "F1 score for Decision Tree w/ optimal depth on testing dataset:  0.276939485933\n"
     ]
    }
   ],
   "source": [
    "# decision trees classifier 441700\n",
    "from sklearn import tree\n",
    "depth = np.arange(10,50,2)\n",
    "y_pred_list = []\n",
    "for i in range(len(depth)):\n",
    "    dt_clf = tree.DecisionTreeClassifier(max_depth=depth[i])\n",
    "    dt_clf.fit(vectors_train,c_train)\n",
    "    y_pred_list.append(dt_clf.predict(vectors_valid))\n",
    "    test = dt_clf.predict(vectors_train)\n",
    "    print(\"Depth: \", depth[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid,y_pred_list[i], average='macro'))\n",
    "\n",
    "# choosing maximum tree depth using validation set and F1 metric\n",
    "f1_list = []\n",
    "for i in range(len(depth)):\n",
    "    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='macro'))\n",
    "\n",
    "depth_opt = depth[f1_list.index(max(f1_list))]\n",
    "print(\"Optimal depth for Decision Tree: \", depth_opt)\n",
    "\n",
    "# f1 metric for train, validation, test with optimal hyperparameter(max tree depth)\n",
    "dt_clf = tree.DecisionTreeClassifier(max_depth=depth_opt)\n",
    "dt_clf.fit(vectors_train,c_train)\n",
    "y_pred_train = dt_clf.predict(vectors_train)\n",
    "y_pred_valid = dt_clf.predict(vectors_valid)\n",
    "y_pred_test = dt_clf.predict(vectors_test)\n",
    "\n",
    "f1_dt_train = metrics.f1_score(c_train,y_pred_train,average='macro')\n",
    "f1_dt_valid = metrics.f1_score(c_valid,y_pred_valid,average='macro')\n",
    "f1_dt_test = metrics.f1_score(c_test,y_pred_test,average='macro')\n",
    "\n",
    "\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on training dataset: \", f1_dt_train)\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on validation dataset: \", f1_dt_valid)\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on testing dataset: \", f1_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.001953125  F1_train:  0.255555336838  F1_valid:  0.229565940536\n",
      "C:  0.009765625  F1_train:  0.478004309589  F1_valid:  0.35971884444\n",
      "C:  0.017578125  F1_train:  0.518311188831  F1_valid:  0.356547063874\n",
      "C:  0.025390625  F1_train:  0.532497847769  F1_valid:  0.360200779967\n",
      "C:  0.033203125  F1_train:  0.537627560544  F1_valid:  0.361617057821\n",
      "C:  0.041015625  F1_train:  0.541079824384  F1_valid:  0.359912042202\n",
      "C:  0.048828125  F1_train:  0.541416559901  F1_valid:  0.359713257903\n",
      "C:  0.056640625  F1_train:  0.544148759337  F1_valid:  0.355816207299\n",
      "C:  0.064453125  F1_train:  0.544131899754  F1_valid:  0.361644335909\n",
      "C:  0.072265625  F1_train:  0.547074884434  F1_valid:  0.351622633531\n",
      "C:  0.080078125  F1_train:  0.542546823204  F1_valid:  0.359710623702\n",
      "C:  0.087890625  F1_train:  0.54834833483  F1_valid:  0.3520599662\n",
      "C:  0.095703125  F1_train:  0.54781515518  F1_valid:  0.357025015403\n",
      "Optimal C for Linear SVM:  0.064453125\n",
      "F1 score for Linear SVM w/ optimal depth on training dataset:  0.545833592797\n",
      "F1 score for Linear SVM w/ optimal depth on validation dataset:  0.357978291118\n",
      "F1 score for Linear SVM w/ optimal depth on testing dataset:  0.364499125388\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "c = np.arange(2**-9,0.1,2**-7)\n",
    "#c = [2**-7, 2**-5, 2**-3, 2**-1, 2**1, 2**3, 2**5, 2**7]\n",
    "y_pred_list = []\n",
    "for i in range(len(c)):\n",
    "    svm_clf = LinearSVC(C=c[i], multi_class=\"ovr\", loss='hinge')\n",
    "    svm_clf.fit(vectors_train,c_train)\n",
    "    y_pred_list.append(svm_clf.predict(vectors_valid))\n",
    "    test = svm_clf.predict(vectors_train)\n",
    "    print(\"C: \", c[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid,y_pred_list[i],average='macro'))\n",
    "    \n",
    "f1_list = []\n",
    "for i in range(len(c)):\n",
    "    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='macro'))\n",
    "\n",
    "c_opt = c[f1_list.index(max(f1_list))]\n",
    "print(\"Optimal C for Linear SVM: \", c_opt)\n",
    "\n",
    "\n",
    "# f1 metric for train, validation, test dataset with optimal c\n",
    "svm_clf=LinearSVC(C=c_opt, multi_class='ovr', loss='hinge')\n",
    "svm_clf.fit(vectors_train,c_train)\n",
    "\n",
    "y_pred_train = svm_clf.predict(vectors_train)\n",
    "y_pred_valid = svm_clf.predict(vectors_valid)\n",
    "y_pred_test = svm_clf.predict(vectors_test)\n",
    "\n",
    "f1_svm_train = metrics.f1_score(c_train,y_pred_train,average='macro')\n",
    "f1_svm_valid = metrics.f1_score(c_valid,y_pred_valid,average='macro')\n",
    "f1_svm_test = metrics.f1_score(c_test,y_pred_test,average='macro')\n",
    "\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on training dataset: \", f1_svm_train)\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on validation dataset: \", f1_svm_valid)\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on testing dataset: \", f1_svm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Bag-of-Words\n",
    "## IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## frequency bag-of-words\n",
    "# imdb\n",
    "data10 = pd.read_csv(\"hwk3_datasets/IMDB-train.txt\", sep=\"\\t\", header=None)\n",
    "data11 = pd.read_csv(\"hwk3_datasets/IMDB-valid.txt\", sep=\"\\t\",  header=None)\n",
    "data12 = pd.read_csv(\"hwk3_datasets/IMDB-test.txt\", sep=\"\\t\",  header=None)\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "for i in range(data10[0].count()):\n",
    "    temp = data10[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data10[0][i] = temp\n",
    "\n",
    "for i in range(data11[0].count()):\n",
    "    temp = data11[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data11[0][i] = temp\n",
    "\n",
    "for i in range(data12[0].count()):\n",
    "    temp = data12[0][i]\n",
    "    temp = ''.join(ch for ch in temp if ch not in exclude)\n",
    "    temp = temp.lower()\n",
    "    data12[0][i] = temp\n",
    "\n",
    "imdb_train = data10.values\n",
    "imdb_valid = data11.values\n",
    "imdb_test = data12.values\n",
    "\n",
    "# generating top 10000 words\n",
    "pre_list_train = {}\n",
    "\n",
    "for i in range(imdb_train.shape[0]):\n",
    "    temp = imdb_train[i][0].split()\n",
    "    for j in range(len(temp)):\n",
    "        if temp[j] in pre_list_train:\n",
    "            pre_list_train[temp[j]] += 1\n",
    "        else:\n",
    "            pre_list_train[temp[j]] = 1\n",
    "            \n",
    "# sort list\n",
    "sorted_list_train = sorted(pre_list_train.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# find top 10000 words\n",
    "top_list_train = []\n",
    "\n",
    "for i in range(10000):\n",
    "    top_list_train.append(sorted_list_train[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create frequency bag-of-words representation for train, validation, test\n",
    "vectors_train = np.zeros(shape=(imdb_train.shape[0],10000))\n",
    "vectors_valid = np.zeros(shape=(imdb_valid.shape[0],10000))\n",
    "vectors_test = np.zeros(shape=(imdb_test.shape[0],10000))\n",
    "\n",
    "for i in range(imdb_train.shape[0]):\n",
    "    words = imdb_train[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        vectors_train[i][j] = words.count(top_list_train[j])\n",
    "        \n",
    "    if (np.sum(vectors_train[i]) == 0):\n",
    "        continue\n",
    "    vectors_train[i] = vectors_train[i]/(np.sum(vectors_train[i]))\n",
    "    \n",
    "    \n",
    "for i in range(imdb_valid.shape[0]):\n",
    "    words = imdb_valid[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        vectors_valid[i][j] = words.count(top_list_train[j])\n",
    "\n",
    "    if (np.sum(vectors_valid[i]) == 0):\n",
    "        continue\n",
    "    vectors_valid[i] = vectors_valid[i]/(np.sum(vectors_valid[i]))\n",
    "    \n",
    "    \n",
    "for i in range(imdb_test.shape[0]):\n",
    "    words = imdb_test[i][0].split(' ')\n",
    "    for j in range(10000):\n",
    "        vectors_test[i][j] = words.count(top_list_train[j])\n",
    "\n",
    "    if (np.sum(vectors_test[i]) == 0):\n",
    "        continue\n",
    "    vectors_test[i] = vectors_test[i]/(np.sum(vectors_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes (y values)\n",
    "c_train = imdb_train[:,1].astype(str)\n",
    "c_valid = imdb_valid[:,1].astype(str)\n",
    "c_test = imdb_test[:,1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for random classifier on training dataset:  0.504599627899\n",
      "F1 score for random classifier on validation dataset:  0.507387684692\n",
      "F1 score for random classifier on test dataset:  0.50047984335\n"
     ]
    }
   ],
   "source": [
    "# random classifier\n",
    "random_results_train = np.empty(shape=(c_train.shape[0]),dtype=int)\n",
    "random_results_valid = np.empty(shape=(c_valid.shape[0]),dtype=int)\n",
    "random_results_test = np.empty(shape=(c_test.shape[0]),dtype=int)\n",
    "\n",
    "for i in range(imdb_train.shape[0]):\n",
    "    random_results_train[i] = np.random.randint(0,2)\n",
    "\n",
    "for i in range(imdb_valid.shape[0]):\n",
    "    random_results_valid[i] = np.random.randint(0,2)\n",
    "    \n",
    "for i in range(imdb_test.shape[0]):\n",
    "    random_results_test[i] = np.random.randint(0,2)\n",
    "    \n",
    "random_results_train = random_results_train.astype(str)\n",
    "random_results_valid = random_results_valid.astype(str)\n",
    "random_results_test = random_results_test.astype(str)\n",
    "\n",
    "f1_random_train = metrics.f1_score(c_train, random_results_train, average='macro')\n",
    "f1_random_valid = metrics.f1_score(c_valid, random_results_valid, average='macro')\n",
    "f1_random_test = metrics.f1_score(c_test, random_results_test, average='macro')\n",
    "print(\"F1 score for random classifier on training dataset: \", f1_random_train)\n",
    "print(\"F1 score for random classifier on validation dataset: \", f1_random_valid)\n",
    "print(\"F1 score for random classifier on test dataset: \", f1_random_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on training dataset:  0.862767587377\n",
      "F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on validation dataset:  0.759488125712\n",
      "F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on test dataset:  0.692712527589\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Bayes multiclass classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#num = np.arange(0.001,1,0.001)  # testing multiple hyperparameters\n",
    "#y_pred_list = []\n",
    "#for i in range(len(num)):\n",
    "    #nb_clf = GaussianNB()\n",
    "    #nb_clf.fit(vectors_train,c_train)\n",
    "    #test = nb_clf.predict(vectors_train)\n",
    "    #y_pred_list.append(nb_clf.predict(vectors_valid))\n",
    "    #print(\"alpha: \", num[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid, y_pred_list[i],average=\"macro\"))\n",
    "    \n",
    "# choosing optimal hyperparameters based on F1 metric\n",
    "#f1_list = []\n",
    "#for i in range(len(num)):\n",
    "#    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='micro'))\n",
    "\n",
    "#alpha_opt = num[f1_list.index(max(f1_list))]\n",
    "#print(\"Optimal hyperparameter for Naive Bayes: \", alpha_opt)\n",
    "\n",
    "# f1 metric with best hyperparameter\n",
    "gs_clf = GaussianNB()\n",
    "gs_clf.fit(vectors_train,c_train)\n",
    "y_pred_train = (gs_clf.predict(vectors_train))\n",
    "y_pred_valid = (gs_clf.predict(vectors_valid))\n",
    "y_pred_test = (gs_clf.predict(vectors_test))\n",
    "\n",
    "f1_nb_train = metrics.f1_score(c_train, y_pred_train, average='macro')\n",
    "f1_nb_valid = metrics.f1_score(c_valid,y_pred_valid, average='macro')\n",
    "f1_nb_test = metrics.f1_score(c_test, y_pred_test,average='macro')\n",
    "\n",
    "print(\"F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on training dataset: \", f1_nb_train)\n",
    "print(\"F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on validation dataset: \", f1_nb_valid)\n",
    "print(\"F1 score for Gaussian Naive Bayes w/ optimal hyperparameter on test dataset: \", f1_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth:  10  F1_train:  0.763416074292  F1_valid:  0.704660863579\n",
      "Depth:  12  F1_train:  0.802531227466  F1_valid:  0.717055500819\n",
      "Depth:  14  F1_train:  0.826350828889  F1_valid:  0.70427251998\n",
      "Depth:  16  F1_train:  0.848036816514  F1_valid:  0.710053267183\n",
      "Depth:  18  F1_train:  0.867548620559  F1_valid:  0.712264779864\n",
      "Depth:  20  F1_train:  0.886586085129  F1_valid:  0.712910698587\n",
      "Depth:  22  F1_train:  0.900531035921  F1_valid:  0.712694702326\n",
      "Depth:  24  F1_train:  0.915733204938  F1_valid:  0.70899295098\n",
      "Depth:  26  F1_train:  0.927959894057  F1_valid:  0.708235143237\n",
      "Depth:  28  F1_train:  0.938093209686  F1_valid:  0.707654049496\n",
      "Depth:  30  F1_train:  0.947396457537  F1_valid:  0.70849019504\n",
      "Depth:  32  F1_train:  0.955821804396  F1_valid:  0.708417761101\n",
      "Depth:  34  F1_train:  0.96149944857  F1_valid:  0.708004339302\n",
      "Depth:  36  F1_train:  0.966238922563  F1_valid:  0.704791122006\n",
      "Depth:  38  F1_train:  0.969980734302  F1_valid:  0.707986672548\n",
      "Depth:  40  F1_train:  0.972518026974  F1_valid:  0.70601330669\n",
      "Depth:  42  F1_train:  0.97431974848  F1_valid:  0.707263420822\n",
      "Depth:  44  F1_train:  0.976923855089  F1_valid:  0.70581990947\n",
      "Depth:  46  F1_train:  0.978192016436  F1_valid:  0.705138857594\n",
      "Depth:  48  F1_train:  0.980260270994  F1_valid:  0.70194648151\n",
      "Optimal depth for Decision Tree:  12\n",
      "F1 score for Decision Tree w/ optimal depth on training dataset:  0.802260095263\n",
      "F1 score for Decision Tree w/ optimal depth on validation dataset:  0.718081063742\n",
      "F1 score for Decision Tree w/ optimal depth on testing dataset:  0.714287475483\n"
     ]
    }
   ],
   "source": [
    "# decision trees classifier 441700\n",
    "from sklearn import tree\n",
    "depth = np.arange(10,50,2)\n",
    "y_pred_list = []\n",
    "for i in range(len(depth)):\n",
    "    dt_clf = tree.DecisionTreeClassifier(max_depth=depth[i])\n",
    "    dt_clf.fit(vectors_train,c_train)\n",
    "    y_pred_list.append(dt_clf.predict(vectors_valid))\n",
    "    test = dt_clf.predict(vectors_train)\n",
    "    print(\"Depth: \", depth[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid,y_pred_list[i], average='macro'))\n",
    "\n",
    "# choosing maximum tree depth using validation set and F1 metric\n",
    "f1_list = []\n",
    "for i in range(len(depth)):\n",
    "    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='macro'))\n",
    "\n",
    "depth_opt = depth[f1_list.index(max(f1_list))]\n",
    "print(\"Optimal depth for Decision Tree: \", depth_opt)\n",
    "\n",
    "# f1 metric for train, validation, test with optimal hyperparameter(max tree depth)\n",
    "dt_clf = tree.DecisionTreeClassifier(max_depth=depth_opt)\n",
    "dt_clf.fit(vectors_train,c_train)\n",
    "y_pred_train = dt_clf.predict(vectors_train)\n",
    "y_pred_valid = dt_clf.predict(vectors_valid)\n",
    "y_pred_test = dt_clf.predict(vectors_test)\n",
    "\n",
    "f1_dt_train = metrics.f1_score(c_train,y_pred_train,average='macro')\n",
    "f1_dt_valid = metrics.f1_score(c_valid,y_pred_valid,average='macro')\n",
    "f1_dt_test = metrics.f1_score(c_test,y_pred_test,average='macro')\n",
    "\n",
    "\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on training dataset: \", f1_dt_train)\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on validation dataset: \", f1_dt_valid)\n",
    "print(\"F1 score for Decision Tree w/ optimal depth on testing dataset: \", f1_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  2048  F1_train:  0.79894655196  F1_valid:  0.750764674521\n",
      "C:  2176  F1_train:  0.945852078467  F1_valid:  0.841279409754\n",
      "C:  2304  F1_train:  0.983466560559  F1_valid:  0.872681359278\n",
      "C:  2432  F1_train:  0.972316941887  F1_valid:  0.861505825367\n",
      "C:  2560  F1_train:  0.983666321046  F1_valid:  0.873395741033\n",
      "C:  2688  F1_train:  0.960076087056  F1_valid:  0.851096328202\n",
      "C:  2816  F1_train:  0.881240974365  F1_valid:  0.79449979524\n",
      "C:  2944  F1_train:  0.98026294417  F1_valid:  0.87035100608\n",
      "Optimal C for Linear SVM:  2560\n",
      "F1 score for Linear SVM w/ optimal depth on training dataset:  0.975522538773\n",
      "F1 score for Linear SVM w/ optimal depth on validation dataset:  0.864848470873\n",
      "F1 score for Linear SVM w/ optimal depth on testing dataset:  0.846073089648\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "c = np.arange(2**11,3000,2**7)\n",
    "#c = [2**-7, 2**-5, 2**-3, 2**-1, 2**1, 2**3, 2**5, 2**7]\n",
    "y_pred_list = []\n",
    "for i in range(len(c)):\n",
    "    svm_clf = LinearSVC(C=c[i], multi_class=\"ovr\", loss='hinge')\n",
    "    svm_clf.fit(vectors_train,c_train)\n",
    "    y_pred_list.append(svm_clf.predict(vectors_valid))\n",
    "    test = svm_clf.predict(vectors_train)\n",
    "    print(\"C: \", c[i], \" F1_train: \", metrics.f1_score(c_train,test,average='macro'), \" F1_valid: \", metrics.f1_score(c_valid,y_pred_list[i],average='macro'))\n",
    "    \n",
    "f1_list = []\n",
    "for i in range(len(c)):\n",
    "    f1_list.append(metrics.f1_score(c_valid, y_pred_list[i], average='macro'))\n",
    "\n",
    "c_opt = c[f1_list.index(max(f1_list))]\n",
    "print(\"Optimal C for Linear SVM: \", c_opt)\n",
    "\n",
    "\n",
    "# f1 metric for train, validation, test dataset with optimal c\n",
    "svm_clf=LinearSVC(C=c_opt, multi_class='ovr', loss='hinge')\n",
    "svm_clf.fit(vectors_train,c_train)\n",
    "\n",
    "y_pred_train = svm_clf.predict(vectors_train)\n",
    "y_pred_valid = svm_clf.predict(vectors_valid)\n",
    "y_pred_test = svm_clf.predict(vectors_test)\n",
    "\n",
    "f1_svm_train = metrics.f1_score(c_train,y_pred_train,average='macro')\n",
    "f1_svm_valid = metrics.f1_score(c_valid,y_pred_valid,average='macro')\n",
    "f1_svm_test = metrics.f1_score(c_test,y_pred_test,average='macro')\n",
    "\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on training dataset: \", f1_svm_train)\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on validation dataset: \", f1_svm_valid)\n",
    "print(\"F1 score for Linear SVM w/ optimal depth on testing dataset: \", f1_svm_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
